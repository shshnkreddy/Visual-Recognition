{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VLAD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q1Tup2NksAL"
      },
      "source": [
        "%matplotlib inline\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks3pnOn0kyJ1",
        "outputId": "67145843-51e1-4688-8b1d-b52b99e9c290"
      },
      "source": [
        "!pip install opencv-contrib-python==4.4.0.44"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-contrib-python==4.4.0.44 in /usr/local/lib/python3.7/dist-packages (4.4.0.44)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==4.4.0.44) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zFQx9Rnk0qU"
      },
      "source": [
        "(train_images,train_labels), (test_images,test_labels) = cifar10.load_data() "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJBEe2DmlCXf"
      },
      "source": [
        "def getDetector(mode):\r\n",
        "  detector = 0\r\n",
        "  if mode == 'sift': detector = cv2.SIFT_create()\r\n",
        "  if mode == 'surf' : detector = cv2.SURF_create()\r\n",
        "  if mode =='brisk' : detector = cv2.BRISK_create()\r\n",
        "  if mode == 'akaze' :  detector = cv2.AKAZE_create() \r\n",
        "  return detector"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuBXKyqOlFYq"
      },
      "source": [
        "def get_features(image, detector):\r\n",
        "  keypoints, descriptors = detector.detectAndCompute(image, None)\r\n",
        "  return keypoints, descriptors"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47SOIq7HlQ_4"
      },
      "source": [
        "def gray(image):\r\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t_pSgjwloDG"
      },
      "source": [
        "detector = getDetector('sift')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBERISavGeO2"
      },
      "source": [
        "train_images = train_images[:10000]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CeUeFG2lWw2"
      },
      "source": [
        "descriptors_lst = []\r\n",
        "for img in train_images:\r\n",
        "  img = gray(img)\r\n",
        "  keypoints, descriptors = get_features(img,detector)\r\n",
        "  \r\n",
        "  if descriptors is not None: descriptors_lst.extend(descriptors)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOO2tycQlbJb"
      },
      "source": [
        "def VLAD(X, visualDictionary) : \r\n",
        "    \r\n",
        "    predictedLabels = visualDictionary.predict(X)\r\n",
        "    centers = visualDictionary.cluster_centers_\r\n",
        "    labels = visualDictionary.labels_\r\n",
        "    k = visualDictionary.n_clusters\r\n",
        "\r\n",
        "    m,d = X.shape\r\n",
        "    V=np.zeros([k,d])\r\n",
        "    #computing the differences\r\n",
        "\r\n",
        "    # for all the clusters (visual words)\r\n",
        "    for i in range(k):\r\n",
        "        # if there is at least one descriptor in that cluster\r\n",
        "        if np.sum(predictedLabels==i)>0:\r\n",
        "            # add the diferences\r\n",
        "            V[i]=np.sum(X[predictedLabels==i,:]-centers[i],axis=0)\r\n",
        "    \r\n",
        "\r\n",
        "    V = V.flatten()\r\n",
        "    # power normalization, also called square-rooting normalization\r\n",
        "    V = np.sign(V)*np.sqrt(np.abs(V))\r\n",
        "\r\n",
        "    # L2 normalization\r\n",
        "\r\n",
        "    V = V/np.sqrt(np.dot(V,V))\r\n",
        "    return V"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHAQD2U7mDCx"
      },
      "source": [
        "def getVLADDescriptors(images, images_lables, visualDic, detector):\r\n",
        "    descriptors = []\r\n",
        "    labels = []\r\n",
        "    \r\n",
        "    count = 0\r\n",
        "    for image in images : \r\n",
        "        #     Re-sizing the image\r\n",
        "        image = cv2.resize(image, (150, 150), interpolation=cv2.INTER_AREA)\r\n",
        "        kp, des = get_features(image,detector)\r\n",
        "        if des is not None : \r\n",
        "            v = VLAD(des, visualDic)\r\n",
        "            descriptors.append(v)\r\n",
        "            labels.append(images_lables[count])\r\n",
        "        count += 1\r\n",
        "            \r\n",
        "            \r\n",
        "    descriptors = np.asarray(descriptors)\r\n",
        "    return descriptors, labels"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3Vnn-lnmMJv",
        "outputId": "869976e6-9c87-45eb-c154-2943b0bc8507"
      },
      "source": [
        "from sklearn.cluster import KMeans \r\n",
        "\r\n",
        "kmeans = KMeans(n_clusters = 64)\r\n",
        "kmeans.fit(descriptors_lst)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=64, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi5CORuPmE8H"
      },
      "source": [
        "x_train, y_train = getVLADDescriptors(train_images, train_labels, kmeans, detector)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRRkKpK7mbeX"
      },
      "source": [
        "x_test, y_test = getVLADDescriptors(test_images, test_labels, kmeans, detector)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GLdoeCZRZWY"
      },
      "source": [
        "y_train = np.array(y_train)\r\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG_RuanJR_5n"
      },
      "source": [
        "y_train = np.ravel(y_train)\r\n",
        "y_test = np.ravel(y_test) "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AxPJCGcroSz"
      },
      "source": [
        "from sklearn.svm import SVC\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzbJpQGktALl"
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvsXSR0iueQ3"
      },
      "source": [
        "x_train = scaler.fit_transform(x_train)\r\n",
        "x_test = scaler.fit_transform(x_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHj-s6o9vEjw"
      },
      "source": [
        "clf = SVC(kernel = 'poly', degree = 3, gamma='auto')\r\n",
        "clf.fit(x_train, y_train)\r\n",
        "\r\n",
        "\r\n",
        "print(clf.score(x_test,y_test) * 100)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJRDX1QJv2JL"
      },
      "source": [
        "lr = LogisticRegression(penalty = 'l2')\r\n",
        "lr.fit(x_train,y_train)\r\n",
        "print(lr.score(x_test,y_test) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fOZUBS31Qe5"
      },
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=10)\r\n",
        "neigh.fit(x_train,y_train)\r\n",
        "neigh.score(x_test[:2000],y_test[:2000]) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMqE0GZe4MSq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}